{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24a63d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   AGE                  10000 non-null  object \n",
      " 1   GENDER               10000 non-null  object \n",
      " 2   RACE                 10000 non-null  object \n",
      " 3   DRIVING_EXPERIENCE   10000 non-null  object \n",
      " 4   EDUCATION            10000 non-null  object \n",
      " 5   INCOME               10000 non-null  object \n",
      " 6   CREDIT_SCORE         9018 non-null   float64\n",
      " 7   VEHICLE_OWNERSHIP    10000 non-null  int64  \n",
      " 8   VEHICLE_YEAR         10000 non-null  object \n",
      " 9   MARRIED              10000 non-null  int64  \n",
      " 10  CHILDREN             10000 non-null  int64  \n",
      " 11  ANNUAL_MILEAGE       9043 non-null   float64\n",
      " 12  VEHICLE_TYPE         10000 non-null  object \n",
      " 13  SPEEDING_VIOLATIONS  10000 non-null  int64  \n",
      " 14  DUIS                 10000 non-null  int64  \n",
      " 15  PAST_ACCIDENTS       10000 non-null  int64  \n",
      " 16  OUTCOME              10000 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(8)\n",
      "memory usage: 1.3+ MB\n",
      "['65+' '16-25' '26-39' '40-64']\n",
      "['female' 'male']\n",
      "['majority' 'minority']\n",
      "['0-9y' '10-19y' '20-29y' '30y+']\n",
      "['high school' 'none' 'university']\n",
      "['upper class' 'poverty' 'working class' 'middle class']\n",
      "['after 2015' 'before 2015']\n",
      "['sedan' 'sports car']\n"
     ]
    }
   ],
   "source": [
    "# Classification:\n",
    "    # Naive Bayes\n",
    "    # Decision Tree\n",
    "    # Random Forest\n",
    "    # Lositic Regression\n",
    "    # Support Vector Machines (or, Support Vector Classification [SVC])\n",
    "    # Neural Network/Perceptron\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.imputation.mice as mice\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier as KC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "data = pd.read_csv('Car_Insurance_Claim.csv')\n",
    "\n",
    "#I put the following two lines here to make life easier when testing the code\n",
    "data.drop(['ID'], axis=1, inplace=True)\n",
    "data.drop(['POSTAL_CODE'], axis=1, inplace=True)\n",
    "\n",
    "data.info()\n",
    "\n",
    "data\n",
    "\n",
    "for x in data.columns:\n",
    "    if data[x].dtype == 'object':\n",
    "        print(data[x].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f4759b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   AGE                  10000 non-null  object \n",
      " 1   GENDER               10000 non-null  object \n",
      " 2   RACE                 10000 non-null  object \n",
      " 3   DRIVING_EXPERIENCE   10000 non-null  object \n",
      " 4   EDUCATION            10000 non-null  object \n",
      " 5   INCOME               10000 non-null  object \n",
      " 6   CREDIT_SCORE         10000 non-null  float64\n",
      " 7   VEHICLE_OWNERSHIP    10000 non-null  int64  \n",
      " 8   VEHICLE_YEAR         10000 non-null  object \n",
      " 9   MARRIED              10000 non-null  int64  \n",
      " 10  CHILDREN             10000 non-null  int64  \n",
      " 11  ANNUAL_MILEAGE       10000 non-null  float64\n",
      " 12  VEHICLE_TYPE         10000 non-null  object \n",
      " 13  SPEEDING_VIOLATIONS  10000 non-null  int64  \n",
      " 14  DUIS                 10000 non-null  int64  \n",
      " 15  PAST_ACCIDENTS       10000 non-null  int64  \n",
      " 16  OUTCOME              10000 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(8)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Data Prep: Impute Missing Data Values using the MICE Imputer from statsmodels\n",
    "\n",
    "data['AGE'].replace({ '65+' : 3, '16-25' : 0, '26-39' : 1, '40-64' : 2 }, inplace=True)\n",
    "data['GENDER'].replace({'female' : 0, 'male' : 1}, inplace=True)\n",
    "data['RACE'].replace({'majority' : 0, 'minority' : 1}, inplace=True)\n",
    "data['DRIVING_EXPERIENCE'].replace({'0-9y' : 0, '10-19y' : 1, '20-29y' : 2, '30y+' : 3}, inplace=True)\n",
    "data['EDUCATION'].replace({'high school' : 1, 'none' : 0, 'university' : 2}, inplace=True)\n",
    "data['INCOME'].replace({'upper class' : 3, 'poverty' : 0, 'working class' : 1, 'middle class' : 2}, inplace=True)\n",
    "data['VEHICLE_YEAR'].replace({'after 2015' : 1, 'before 2015' : 0}, inplace=True)\n",
    "data['VEHICLE_TYPE'].replace({'sedan' : 0, 'sports car' : 1}, inplace=True)\n",
    "\n",
    "imp = mice.MICEData(data)\n",
    "imp.set_imputer('CREDIT_SCORE')\n",
    "for x in range(0,5):\n",
    "    imp.update_all()\n",
    "    if x == 4:\n",
    "        data = imp.data\n",
    "\n",
    "data['AGE'].replace({ 3 : '65+' , 0 : '16-25', 1 : '26-39', 2 : '40-64' }, inplace=True)\n",
    "data['GENDER'].replace({ 0 : 'female', 1 : 'male' }, inplace=True)\n",
    "data['RACE'].replace({0 : 'majority', 1 : 'minority'}, inplace=True)\n",
    "data['DRIVING_EXPERIENCE'].replace({ 0 :'0-9y', 1 : '10-19y', 2 : '20-29y', 3 : '30y+'}, inplace=True)\n",
    "data['EDUCATION'].replace({ 1 : 'high school', 0 : 'none', 2 : 'university'}, inplace=True)\n",
    "data['INCOME'].replace({3 : 'upper class', 0: 'poverty', 1 : 'working class', 2 : 'middle class'}, inplace=True)\n",
    "data['VEHICLE_YEAR'].replace({ 1 :'after 2015', 0 : 'before 2015'}, inplace=True)\n",
    "data['VEHICLE_TYPE'].replace({ 0 :'sedan', 1 : 'sports car'}, inplace=True)        \n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4219ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and Y\n",
    "all_features = data.loc[:, data.columns != 'OUTPUT']\n",
    "outcome = data[['OUTCOME']].values\n",
    "\n",
    "# Build the Column Transformer\n",
    "ct = ColumnTransformer([('OrdEncode', OrdinalEncoder(), ['AGE', 'INCOME', 'DRIVING_EXPERIENCE']), ('OHEncode', OneHotEncoder(), ['GENDER', 'RACE', 'EDUCATION', 'VEHICLE_YEAR', 'VEHICLE_TYPE'])], remainder='passthrough')\n",
    "# data_ct.output_indices_\n",
    "\n",
    "data_ct = ct.fit_transform(all_features)\n",
    "# Scaling the data \n",
    "scaler = StandardScaler()\n",
    "all_features_scaled = scaler.fit_transform(data_ct)\n",
    "\n",
    "# train_test_split()\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_features_scaled, outcome, test_size=.33)\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2254729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98955223880597"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive_Bayes\n",
    "scaler = MinMaxScaler()\n",
    "all_features_minmax = scaler.fit_transform(data_ct)\n",
    "X_train_minmax, X_test_minmax, y_train_minmax, y_test_minmax = train_test_split(all_features_minmax, outcome, test_size=.33, random_state=1)\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "y_train_minmax = np.ravel(y_train_minmax)\n",
    "y_test_minmax = np.ravel(y_test_minmax)\n",
    "\n",
    "NB_cv_score = cross_val_score(classifier, X_train_minmax, y_train_minmax, cv=10)\n",
    "\n",
    "NB_cv_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b984546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifiers\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state=1)  \n",
    "DTC.fit(X_train, y_train)\n",
    "DTC_base_cv_score = cross_val_score(DTC, X_test, y_test, cv=10)\n",
    "print(DTC_base_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52b9aeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "RFC = RandomForestClassifier(random_state=1)\n",
    "RFC.fit(X_train, y_train)\n",
    "RFC_cv_scores = cross_val_score(RFC, X_test, y_test, cv=10)\n",
    "RFC_cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73e1f0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9624242424242423"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN\n",
    "\n",
    "KNN = neighbors.KNeighborsClassifier(n_neighbors=20)\n",
    "KNN.fit(X_train, y_train)\n",
    "cv_scores = cross_val_score(KNN, X_test, y_test, cv=10)\n",
    "\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "761cfa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.9606060606060606\n",
      "3 0.9724242424242424\n",
      "4 0.9672727272727272\n",
      "5 0.9739393939393939\n",
      "6 0.97\n",
      "7 0.9727272727272729\n",
      "8 0.9684848484848485\n",
      "9 0.9703030303030303\n",
      "10 0.9672727272727272\n",
      "11 0.9687878787878788\n",
      "12 0.966969696969697\n",
      "13 0.9690909090909091\n",
      "14 0.9642424242424242\n",
      "15 0.9660606060606062\n",
      "16 0.9633333333333333\n",
      "17 0.9651515151515151\n",
      "18 0.9624242424242425\n",
      "19 0.9648484848484848\n",
      "20 0.9624242424242423\n",
      "21 0.9630303030303029\n",
      "22 0.9615151515151515\n",
      "23 0.9651515151515152\n",
      "24 0.9615151515151515\n",
      "25 0.9624242424242425\n"
     ]
    }
   ],
   "source": [
    "#use a loop to see if the mean of that is a better value\n",
    "\n",
    "for n in range(2,26):\n",
    "    KNN = neighbors.KNeighborsClassifier(n_neighbors=n)\n",
    "    KNN.fit(X_train, y_train)\n",
    "    KNN_loop_cv_score = cross_val_score(KNN, X_test, y_test, cv=10)\n",
    "    print(n, KNN_loop_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "613410ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999090909090909"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM (or in this case, SVC)\n",
    "\n",
    "#the default 'rbf' kernel\n",
    "\n",
    "C = 1.0\n",
    "svc = svm.SVC(kernel='rbf', C=C)\n",
    "svc.fit(X_train, y_train)\n",
    "cv_scores = cross_val_score(svc, X_test, y_test, cv=10)\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a608aabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM (or in this case, SVC)\n",
    "\n",
    "#the linear kernel\n",
    "\n",
    "C = 1.0\n",
    "svc = svm.SVC(kernel='linear', C=C)\n",
    "svc.fit(X_train, y_train)\n",
    "cv_scores = cross_val_score(svc, X_test, y_test, cv=10)\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96074eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM (or in this case, SVC)\n",
    "\n",
    "#the poly kernel\n",
    "\n",
    "C = 1.0\n",
    "svc = svm.SVC(kernel='poly', C=C)\n",
    "svc.fit(X_train, y_train)\n",
    "cv_scores = cross_val_score(svc, X_test, y_test, cv=10)\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca7c99bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9803030303030302"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM (or in this case, SVC)\n",
    "\n",
    "#the sigmoid kernel\n",
    "\n",
    "C = 1.0\n",
    "svc = svm.SVC(kernel='sigmoid', C=C)\n",
    "svc.fit(X_train, y_train)\n",
    "cv_scores = cross_val_score(svc, X_test, y_test, cv=10)\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe7059b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_test, y_test)\n",
    "cv_scores = cross_val_score(LR, X_test, y_test, cv=10)\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0984c557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network\n",
    "\n",
    "# Create the NN model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, kernel_initializer='normal', input_dim=23, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Calculate the estimator\n",
    "estimator = KC(build_fn=create_model, epochs=100, verbose=0)\n",
    "\n",
    "# Score it and take the mean\n",
    "cv_scores = cross_val_score(estimator, X_test, y_test, cv=10)\n",
    "cv_scores.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
